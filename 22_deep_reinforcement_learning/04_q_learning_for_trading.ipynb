{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning for Trading - Deep Q-learning & the stock market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a trading agent, we need to create a market environment that provides price and other information, offers trading-related actions, and keeps track of the portfolio to reward the agent accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Design an OpenAI trading environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenAI Gym allows for the design, registration, and utilization of environments that adhere to its architecture, as described in its [documentation](https://github.com/openai/gym/tree/master/gym/envs#how-to-create-new-environments-for-gym). The [trading_env.py](trading_env.py) file implements an example that illustrates how to create a class that implements the requisite `step()` and `reset()` methods.\n",
    "\n",
    "The trading environment consists of three classes that interact to facilitate the agent's activities:\n",
    " 1. The `DataSource` class loads a time series, generates a few features, and provides the latest observation to the agent at each time step. \n",
    " 2. `TradingSimulator` tracks the positions, trades and cost, and the performance. It also implements and records the results of a buy-and-hold benchmark strategy. \n",
    " 3. `TradingEnvironment` itself orchestrates the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book chapter explains these elements in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic trading game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the agent, we need to set up a simple game with a limited set of options, a relatively low-dimensional state, and other parameters that can be easily modified and extended.\n",
    "\n",
    "More specifically, the environment samples a stock price time series for a single ticker using a random start date to simulate a trading period that, by default, contains 252 days, or 1 year. The state contains the (scaled) price and volume, as well as some technical indicators like the percentile ranks of price and volume, a relative strength index (RSI), as well as 5- and 21-day returns. The agent can choose from three actions:\n",
    "\n",
    "- **Buy**: Invest capital for a long position in the stock\n",
    "- **Flat**: Hold cash only\n",
    "- **Sell short**: Take a short position equal to the amount of capital\n",
    "\n",
    "The environment accounts for trading cost, which is set to 10bps by default. It also deducts a 1bps time cost per period. It tracks the net asset value (NAV) of the agent's portfolio and compares it against the market portfolio (which trades frictionless to raise the bar for the agent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same DDQN agent and neural network architecture that successfully learned to navigate the Lunar Lander environment. We let exploration continue for 500,000 time steps (~2,000 1yr trading periods) with linear decay of Îµ to 0.1 and exponential decay at a factor of 0.9999 thereafter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:29.634858Z",
     "start_time": "2021-02-25T06:20:27.942424Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from collections import deque\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import gym\n",
    "from gym.envs.registration import register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:29.638316Z",
     "start_time": "2021-02-25T06:20:29.636097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# %%\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# %%\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "# %%\n",
    "\n",
    "results_path = Path('results', 'trading_bot')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)\n",
    "\n",
    "# %% md\n",
    "\n",
    "### Helper functions\n",
    "\n",
    "# %%\n",
    "\n",
    "def format_time(t):\n",
    "    m_, s = divmod(t, 60)\n",
    "    h, m = divmod(m_, 60)\n",
    "    return '{:02.0f}:{:02.0f}:{:02.0f}'.format(h, m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Gym Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the custom environment, just like with the Lunar Lander environment, we need to register it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:29.688161Z",
     "start_time": "2021-02-25T06:20:29.681742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Trading costs: 0.10% | Time costs: 0.01%'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_days = 252\n",
    "\n",
    "# %%\n",
    "\n",
    "register(\n",
    "    id='trading-v0',\n",
    "    entry_point='trading_env:TradingEnvironment',\n",
    "    max_episode_steps=trading_days\n",
    ")\n",
    "\n",
    "# %% md\n",
    "\n",
    "### Initialize Trading Environment\n",
    "\n",
    "# %% md\n",
    "\n",
    "## We can instantiate the environment by using the desired trading costs and ticker:\n",
    "\n",
    "# %%\n",
    "\n",
    "trading_cost_bps = 1e-3\n",
    "time_cost_bps = 1e-4\n",
    "\n",
    "# %%\n",
    "\n",
    "f'Trading costs: {trading_cost_bps:.2%} | Time costs: {time_cost_bps:.2%}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.544485Z",
     "start_time": "2021-02-25T06:20:29.698083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trading_env:trading_env logger started.\n",
      "INFO:trading_env:loading data for AAPL...\n",
      "INFO:trading_env:got data for AAPL...\n",
      "INFO:trading_env:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1570 entries, 1 to 1618\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   returns  1570 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 24.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "[42]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_environment = gym.make('trading-v0')\n",
    "trading_environment.env.trading_days = trading_days\n",
    "trading_environment.env.trading_cost_bps = trading_cost_bps\n",
    "trading_environment.env.time_cost_bps = time_cost_bps\n",
    "trading_environment.env.ticker = 'AAPL'\n",
    "trading_environment.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Environment Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.548145Z",
     "start_time": "2021-02-25T06:20:32.545830Z"
    }
   },
   "outputs": [],
   "source": [
    "state_dim = trading_environment.observation_space.shape[0]\n",
    "num_actions = trading_environment.action_space.n\n",
    "max_episode_steps = trading_environment.spec.max_episode_steps\n",
    "\n",
    "\n",
    "# %% md\n",
    "\n",
    "## Define Trading Agent\n",
    "\n",
    "# %%\n",
    "\n",
    "class DDQNAgent:\n",
    "    def __init__(self, state_dim,\n",
    "                 num_actions,\n",
    "                 learning_rate,\n",
    "                 gamma,\n",
    "                 epsilon_start,\n",
    "                 epsilon_end,\n",
    "                 epsilon_decay_steps,\n",
    "                 epsilon_exponential_decay,\n",
    "                 replay_capacity,\n",
    "                 architecture,\n",
    "                 l2_reg,\n",
    "                 tau,\n",
    "                 batch_size):\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.experience = deque([], maxlen=replay_capacity)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.architecture = architecture\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "        self.online_network = self.build_model()\n",
    "        self.target_network = self.build_model(trainable=False)\n",
    "        self.update_target()\n",
    "\n",
    "        self.epsilon = epsilon_start\n",
    "        self.epsilon_decay_steps = epsilon_decay_steps\n",
    "        self.epsilon_decay = (epsilon_start - epsilon_end) / epsilon_decay_steps\n",
    "        self.epsilon_exponential_decay = epsilon_exponential_decay\n",
    "        self.epsilon_history = []\n",
    "\n",
    "        self.total_steps = self.train_steps = 0\n",
    "        self.episodes = self.episode_length = self.train_episodes = 0\n",
    "        self.steps_per_episode = []\n",
    "        self.episode_reward = 0\n",
    "        self.rewards_history = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tau = tau\n",
    "        self.losses = []\n",
    "        self.idx = tf.range(batch_size)\n",
    "        self.train = True\n",
    "\n",
    "    def build_model(self, trainable=True):\n",
    "        layers = []\n",
    "        n = len(self.architecture)\n",
    "        for i, units in enumerate(self.architecture, 1):\n",
    "            layers.append(Dense(units=units,\n",
    "                                input_dim=self.state_dim if i == 1 else None,\n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=l2(self.l2_reg),\n",
    "                                name=f'Dense_{i}',\n",
    "                                trainable=trainable))\n",
    "        layers.append(Dropout(.1))\n",
    "        layers.append(Dense(units=self.num_actions,\n",
    "                            trainable=trainable,\n",
    "                            name='Output'))\n",
    "        model = Sequential(layers)\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target(self):\n",
    "        self.target_network.set_weights(self.online_network.get_weights())\n",
    "\n",
    "    def epsilon_greedy_policy(self, state):\n",
    "        print(state)\n",
    "        print(\"end state\")\n",
    "        self.total_steps += 1\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.num_actions)\n",
    "        q = self.online_network.predict(state)\n",
    "        return np.argmax(q, axis=1).squeeze()\n",
    "\n",
    "    def memorize_transition(self, s, a, r, s_prime, not_done):\n",
    "        if not_done:\n",
    "            self.episode_reward += r\n",
    "            self.episode_length += 1\n",
    "        else:\n",
    "            if self.train:\n",
    "                if self.episodes < self.epsilon_decay_steps:\n",
    "                    self.epsilon -= self.epsilon_decay\n",
    "                else:\n",
    "                    self.epsilon *= self.epsilon_exponential_decay\n",
    "\n",
    "            self.episodes += 1\n",
    "            self.rewards_history.append(self.episode_reward)\n",
    "            self.steps_per_episode.append(self.episode_length)\n",
    "            self.episode_reward, self.episode_length = 0, 0\n",
    "\n",
    "        self.experience.append((s, a, r, s_prime, not_done))\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if self.batch_size > len(self.experience):\n",
    "            return\n",
    "        minibatch = map(np.array, zip(*sample(self.experience, self.batch_size)))\n",
    "        states, actions, rewards, next_states, not_done = minibatch\n",
    "\n",
    "        next_q_values = self.online_network.predict_on_batch(next_states)\n",
    "        best_actions = tf.argmax(next_q_values, axis=1)\n",
    "\n",
    "        next_q_values_target = self.target_network.predict_on_batch(next_states)\n",
    "        target_q_values = tf.gather_nd(next_q_values_target,\n",
    "                                       tf.stack((self.idx, tf.cast(best_actions, tf.int32)), axis=1))\n",
    "\n",
    "        targets = rewards + not_done * self.gamma * target_q_values\n",
    "\n",
    "        q_values = self.online_network.predict_on_batch(states)\n",
    "        q_values[[self.idx, actions]] = targets\n",
    "\n",
    "        loss = self.online_network.train_on_batch(x=states, y=q_values)\n",
    "        self.losses.append(loss)\n",
    "\n",
    "        if self.total_steps % self.tau == 0:\n",
    "            self.update_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.575368Z",
     "start_time": "2021-02-25T06:20:32.565067Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma = .99,  # discount factor\n",
    "tau = 100  # target network update frequency\n",
    "\n",
    "# %% md\n",
    "\n",
    "### NN Architecture\n",
    "\n",
    "# %%\n",
    "\n",
    "architecture = (256, 256)  # units per layer\n",
    "learning_rate = 0.0001  # learning rate\n",
    "l2_reg = 1e-6  # L2 regularization\n",
    "\n",
    "# %% md\n",
    "\n",
    "### Experience Replay\n",
    "\n",
    "# %%\n",
    "\n",
    "replay_capacity = int(1e6)\n",
    "batch_size = 4096\n",
    "\n",
    "# %% md\n",
    "\n",
    "### $\\epsilon$-greedy Policy\n",
    "\n",
    "# %%\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = .01\n",
    "epsilon_decay_steps = 250\n",
    "epsilon_exponential_decay = .99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DDQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [TensorFlow](https://www.tensorflow.org/) to create our Double Deep Q-Network ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.613239Z",
     "start_time": "2021-02-25T06:20:32.604766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_1 (Dense)             (None, 256)               512       \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,075\n",
      "Trainable params: 67,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# %%\n",
    "\n",
    "ddqn = DDQNAgent(state_dim=state_dim,\n",
    "                 num_actions=num_actions,\n",
    "                 learning_rate=learning_rate,\n",
    "                 gamma=gamma,\n",
    "                 epsilon_start=epsilon_start,\n",
    "                 epsilon_end=epsilon_end,\n",
    "                 epsilon_decay_steps=epsilon_decay_steps,\n",
    "                 epsilon_exponential_decay=epsilon_exponential_decay,\n",
    "                 replay_capacity=replay_capacity,\n",
    "                 architecture=architecture,\n",
    "                 l2_reg=l2_reg,\n",
    "                 tau=tau,\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "# %%\n",
    "\n",
    "ddqn.online_network.summary()\n",
    "\n",
    "# %% md\n",
    "\n",
    "## Run Experiment\n",
    "\n",
    "# %% md\n",
    "\n",
    "### Set parameters\n",
    "\n",
    "# %%\n",
    "\n",
    "total_steps = 0\n",
    "max_episodes = 10\n",
    "\n",
    "# %% md\n",
    "\n",
    "### Initialize variables\n",
    "\n",
    "# %%\n",
    "\n",
    "episode_time, navs, market_navs, diffs, episode_eps = [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.752721Z",
     "start_time": "2021-02-25T06:20:32.742471Z"
    }
   },
   "outputs": [],
   "source": [
    "def track_results(episode, nav_ma_100, nav_ma_10,\n",
    "                  market_nav_100, market_nav_10,\n",
    "                  win_ratio, total, epsilon):\n",
    "    time_ma = np.mean([episode_time[-100:]])\n",
    "    T = np.sum(episode_time)\n",
    "    \n",
    "    template = '{:>4d} | {} | Agent: {:>6.1%} ({:>6.1%}) | '\n",
    "    template += 'Market: {:>6.1%} ({:>6.1%}) | '\n",
    "    template += 'Wins: {:>5.1%} | eps: {:>6.3f}'\n",
    "    print(template.format(episode, format_time(total), \n",
    "                          nav_ma_100-1, nav_ma_10-1, \n",
    "                          market_nav_100-1, market_nav_10-1, \n",
    "                          win_ratio, epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00048497]]\n",
      "end state\n",
      "0.0\n",
      "[[-0.00222384]]\n",
      "end state\n",
      "-1.0\n",
      "[[0.00056733]]\n",
      "end state\n",
      "0.0\n",
      "[[0.00117452]]\n",
      "end state\n",
      "1.0\n",
      "[[0.00093042]]\n",
      "end state\n",
      "-1.0\n",
      "[[-4.0415471e-05]]\n",
      "end state\n",
      "1.0\n",
      "[[-0.00242503]]\n",
      "end state\n",
      "0.0\n",
      "[[0.00024309]]\n",
      "end state\n",
      "0.0\n",
      "[[0.00089112]]\n",
      "end state\n",
      "-1.0\n",
      "[[-0.00044516]]\n",
      "end state\n",
      "0.0\n",
      "[[-0.00538483]]\n",
      "end state\n",
      "-1.0\n",
      "[[-0.00052919]]\n",
      "end state\n",
      "1.0\n",
      "[[0.00012218]]\n",
      "end state\n",
      "1.0\n",
      "[[-0.00464245]]\n",
      "end state\n",
      "1.0\n",
      "[[-0.00167744]]\n",
      "end state\n",
      "1.0\n",
      "[[-0.00745871]]\n",
      "end state\n",
      "-1.0\n",
      "[[0.00074322]]\n",
      "end state\n",
      "1.0\n",
      "[[-0.00107274]]\n",
      "end state\n",
      "-1.0\n",
      "[[-0.00644335]]\n",
      "end state\n",
      "-1.0\n",
      "[[0.00922885]]\n",
      "end state\n",
      "0.0\n",
      "[[-0.00230671]]\n",
      "end state\n",
      "0.0\n",
      "[[-0.00169275]]\n",
      "end state\n",
      "1.0\n",
      "[[-0.00186104]]\n",
      "end state\n",
      "-1.0\n",
      "[[0.00886679]]\n",
      "end state\n",
      "1.0\n",
      "[[-0.008871]]\n",
      "end state\n",
      "0.0\n",
      "[[0.00812166]]\n",
      "end state\n",
      "0.0\n",
      "[[-0.00065765]]\n",
      "end state\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_4628/906683491.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepisode_step\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_episode_steps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m         \u001B[0maction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mddqn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepsilon_greedy_policy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthis_state\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate_dim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m         \u001B[0mnext_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrading_environment\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m         ddqn.memorize_transition(this_state, \n",
      "\u001B[1;32mc:\\users\\erich\\desktop\\pyvirtenvs\\mqpbook\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     16\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001B[1;32m---> 18\u001B[1;33m         \u001B[0mobservation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_max_episode_steps\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\MQP\\TestCode\\Machine-Learning-for-Algorithmic-Trading-Second-Edition\\22_deep_reinforcement_learning\\trading_env.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    274\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maction_space\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontains\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'{} {} invalid'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    275\u001B[0m         \u001B[0mobservation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_source\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtake_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 276\u001B[1;33m         reward, info = self.simulator.take_step(action=action,\n\u001B[0m\u001B[0;32m    277\u001B[0m                                                 market_return=observation[0])\n\u001B[0;32m    278\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mobservation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\MQP\\TestCode\\Machine-Learning-for-Algorithmic-Trading-Second-Edition\\22_deep_reinforcement_learning\\trading_env.py\u001B[0m in \u001B[0;36mtake_step\u001B[1;34m(self, action, market_return)\u001B[0m\n\u001B[0;32m    190\u001B[0m         \u001B[0mn_trades\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mend_position\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mstart_position\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    191\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstart_position\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 192\u001B[1;33m         \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    193\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpositions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mend_position\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    194\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrades\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mn_trades\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "results = []\n",
    "for episode in range(1, max_episodes + 1):\n",
    "    this_state = trading_environment.reset()\n",
    "    for episode_step in range(max_episode_steps):\n",
    "        action = ddqn.epsilon_greedy_policy(this_state.reshape(-1, state_dim))\n",
    "        next_state, reward, done, _ = trading_environment.step(action)\n",
    "    \n",
    "        ddqn.memorize_transition(this_state, \n",
    "                                 action, \n",
    "                                 reward, \n",
    "                                 next_state, \n",
    "                                 0.0 if done else 1.0)\n",
    "        if ddqn.train:\n",
    "            ddqn.experience_replay()\n",
    "        if done:\n",
    "            break\n",
    "        this_state = next_state\n",
    "\n",
    "    # get DataFrame with seqence of actions, returns and nav values\n",
    "    result = trading_environment.env.simulator.result()\n",
    "    \n",
    "    # get results of last step\n",
    "    final = result.iloc[-1]\n",
    "\n",
    "    # apply return (net of cost) of last action to last starting nav \n",
    "    nav = final.nav * (1 + final.strategy_return)\n",
    "    navs.append(nav)\n",
    "\n",
    "    # market nav \n",
    "    market_nav = final.market_nav\n",
    "    market_navs.append(market_nav)\n",
    "\n",
    "    # track difference between agent an market NAV results\n",
    "    diff = nav - market_nav\n",
    "    diffs.append(diff)\n",
    "    \n",
    "    if episode % 10 == 0:\n",
    "        track_results(episode, \n",
    "                      # show mov. average results for 100 (10) periods\n",
    "                      np.mean(navs[-100:]), \n",
    "                      np.mean(navs[-10:]), \n",
    "                      np.mean(market_navs[-100:]), \n",
    "                      np.mean(market_navs[-10:]), \n",
    "                      # share of agent wins, defined as higher ending nav\n",
    "                      np.sum([s > 0 for s in diffs[-100:]])/min(len(diffs), 100), \n",
    "                      time() - start, ddqn.epsilon)\n",
    "    if len(diffs) > 25 and all([r > 0 for r in diffs[-25:]]):\n",
    "        print(result.tail())\n",
    "        break\n",
    "\n",
    "trading_environment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12172/3334327883.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdiffs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m results = pd.DataFrame({'Episode': list(range(1, episode+1)),\n\u001B[0m\u001B[0;32m      3\u001B[0m                         \u001B[1;34m'Agent'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnavs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                         \u001B[1;34m'Market'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mmarket_navs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                         'Difference': diffs}).set_index('Episode')\n",
      "\u001B[1;32mc:\\users\\erich\\desktop\\pyvirtenvs\\mqpbook\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    612\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    613\u001B[0m             \u001B[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 614\u001B[1;33m             \u001B[0mmgr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict_to_mgr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtyp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmanager\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    615\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMaskedArray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    616\u001B[0m             \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmrecords\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmrecords\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\erich\\desktop\\pyvirtenvs\\mqpbook\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    462\u001B[0m         \u001B[1;31m# TODO: can we get rid of the dt64tz special case above?\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 464\u001B[1;33m     return arrays_to_mgr(\n\u001B[0m\u001B[0;32m    465\u001B[0m         \u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_names\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtyp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtyp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    466\u001B[0m     )\n",
      "\u001B[1;32mc:\\users\\erich\\desktop\\pyvirtenvs\\mqpbook\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36marrays_to_mgr\u001B[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[0;32m    117\u001B[0m         \u001B[1;31m# figure out the index, if necessary\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 119\u001B[1;33m             \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_extract_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    120\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m             \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mensure_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\erich\\desktop\\pyvirtenvs\\mqpbook\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_extract_index\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    633\u001B[0m             \u001B[0mlengths\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mraw_lengths\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    634\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 635\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"All arrays must be of the same length\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    636\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    637\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mhave_dicts\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "print(len(diffs))\n",
    "results = pd.DataFrame({'Episode': list(range(1, episode+1)),\n",
    "                        'Agent': navs,\n",
    "                        'Market': market_navs,\n",
    "                        'Difference': diffs}).set_index('Episode')\n",
    "\n",
    "results['Strategy Wins (%)'] = (results.Difference > 0).rolling(100).sum()\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.023Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv(results_path / 'results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    sns.distplot(results.Difference)\n",
    "    sns.despine()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following diagram shows the rolling average of agent and market returns over 100 periods on the left, and the share of the last 100 periods the agent outperformed the market on the right. It uses AAPL stock data with some 9,000 daily price and volume observations, corresponding to ~35 years of data. \n",
    "\n",
    "It shows how the agent's performance improves significantly while exploring at a higher rate over the first ~600 periods (that is, years) and approaches a level where it outperforms the market around 40 percent of the time, despite transaction costs. In an increasing number of instances, it beats the market over half the time out of 100 periods:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 4), sharey=True)\n",
    "\n",
    "df1 = (results[['Agent', 'Market']]\n",
    "       .sub(1)\n",
    "       .rolling(100)\n",
    "       .mean())\n",
    "df1.plot(ax=axes[0],\n",
    "         title='Annual Returns (Moving Average)',\n",
    "         lw=1)\n",
    "\n",
    "df2 = results['Strategy Wins (%)'].div(100).rolling(50).mean()\n",
    "df2.plot(ax=axes[1],\n",
    "         title='Agent Outperformance (%, Moving Average)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.yaxis.set_major_formatter(\n",
    "        FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        FuncFormatter(lambda x, _: '{:,.0f}'.format(x)))\n",
    "axes[1].axhline(.5, ls='--', c='k', lw=1)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_path / 'performance', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 1 to 100\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Agent              100 non-null    float64\n",
      " 1   Market             100 non-null    float64\n",
      " 2   Difference         100 non-null    float64\n",
      " 3   Strategy Wins (%)  1 non-null      float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.9 KB\n"
     ]
    }
   ],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following diagram shows the rolling average of agent and market returns over 100 periods on the left, and the share of the last 100 periods the agent outperformed the market on the right. It uses AAPL stock data with some 9,000 daily price and volume observations, corresponding to ~35 years of data. \n",
    "\n",
    "It shows how the agent's performance improves significantly while exploring at a higher rate over the first ~600 periods (that is, years) and approaches a level where it outperforms the market around 40 percent of the time, despite transaction costs. In an increasing number of instances, it beats the market over half the time out of 100 periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1008x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 4), sharey=True)\n",
    "\n",
    "df1 = (results[['Agent', 'Market']]\n",
    "       .sub(1)\n",
    "       .rolling(100)\n",
    "       .mean())\n",
    "df1.plot(ax=axes[0],\n",
    "         title='Annual Returns (Moving Average)',\n",
    "         lw=1)\n",
    "\n",
    "df2 = results['Strategy Wins (%)'].div(100).rolling(50).mean()\n",
    "df2.plot(ax=axes[1],\n",
    "         title='Agent Outperformance (%, Moving Average)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.yaxis.set_major_formatter(\n",
    "        FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        FuncFormatter(lambda x, _: '{:,.0f}'.format(x)))\n",
    "axes[1].axhline(.5, ls='--', c='k', lw=1)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_path / 'performance', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This relatively simple agent uses **no information beyond the latest market data and the reward signal** compared to the machine learning models we covered elsewhere in this book. Nonetheless, it learns to make a profit and achieve performance similar to that of the market (after training on <1,000 years' worth of data, which takes only a fraction of the time on a GPU).\n",
    "\n",
    "Keep in mind that using a single stock also increases the **risk of overfitting** to the data â by a lot. You can test your trained agent on new data using the saved model (see the notebook for Lunar Lander).\n",
    "\n",
    "In summary, we have demonstrated the **mechanics of setting up an RL trading environment** and experimented with a basic agent that uses a small number of technical indicators. You should **try to extend both the environment and the agent** - for example, by allowing it to choose from several assets, size the positions, and manage risks.\n",
    "\n",
    "Reinforcement learning is often considered **one of the most promising approaches to algorithmic trading** because it most accurately models the task an investor is facing. However, our dramatically simplified examples illustrate that creating a **realistic environment poses a considerable challenge**. Moreover, deep reinforcement learning that has achieved impressive breakthroughs in other domains may face greater obstacles given the noisy nature of financial data, which makes it even harder to learn a value function based on delayed rewards.\n",
    "\n",
    "Nonetheless, the substantial interest in this subject makes it likely that institutional investors are working on larger-scale experiments that may yield tangible results. An interesting complementary approach beyond the scope of this book is **Inverse Reinforcement Learning**, which aims to identify the reward function of an agent(for example, a human trader) given its observed behavior; see [Arora and Doshi (2019)](https://www.semanticscholar.org/paper/A-Survey-of-Inverse-Reinforcement-Learning%3A-Methods-Arora-Doshi/9d4d8509f6da094a7c31e063f307e0e8592db27f) for a survey and [Roa-Vicens et al. (2019)](https://deepai.org/publication/towards-inverse-reinforcement-learning-for-limit-order-book-dynamics) for an application on trading in the limit-order book context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.906px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}